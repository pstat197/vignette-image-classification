{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65870bf1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dea22f61",
   "metadata": {},
   "source": [
    "# Vignette for image classification \n",
    "\n",
    "This vignette explores the progression from classical machine learning to deep learning for image classification using the Cats vs Dogs dataset from Kaggle. We start by building baseline models—SVM and XGBoost—trained on flattened image vectors. These baselines help show the limitations of classical ML when images are reduced to tabular form. We then introduce a Convolutional Neural Network (CNN), which uses the spatial structure of images, and briefly discuss Vision Transformers (ViT), which apply transformer architectures to sequences of image patches. Together, these models illustrate the evolution from traditional approaches to modern architectures, highlighting both the strengths and weaknesses of each in image classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7c5c23",
   "metadata": {},
   "source": [
    "Data:  The Cats vs Dogs dataset from Kaggle contains 25,000 real-world images of cats and dogs, labeled as 0 or 1. Half of them are in train1, and half are in test. Because the dataset is too large to store on GitHub, it is kept locally under data/ and excluded through .gitignore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8825fc58",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Before training any models, the images must be standardized and prepared in a format suitable for both classical machine learning and deep learning methods. This involves resizing the images, extracting labels from filenames, and converting each image into numerical arrays that serve as model inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c16452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "#Function for Non-Deep Learning Models\n",
    "def prepare_ml_data(data_path, target_size=(64, 64)):\n",
    "    filenames = [f for f in os.listdir(data_path) if f.endswith('.jpg')]\n",
    "    X, y = [], []\n",
    "    for filename in filenames:\n",
    "        img = Image.open(os.path.join(data_path, filename)).convert('RGB').resize(target_size)\n",
    "        img_array = np.array(img).astype(np.float32) / 255.0\n",
    "        X.append(img_array.flatten())\n",
    "        y.append(0 if filename.split('.')[0] == 'cat' else 1)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8938ba",
   "metadata": {},
   "source": [
    "The prepare_ml_data function loads all .jpg images from a given folder and preprocesses them for classical machine learning models. Each image is opened, converted to RGB, resized to 64×64 pixels, and normalized to values between 0 and 1. The image is then flattened into a one-dimensional vector so models like SVM and XGBoost can use it as tabular input. Labels are extracted from the filename, assigning 0 for cats and 1 for dogs. The function returns two NumPy arrays: X containing the flattened image data and y containing the corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499212b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for Deep Learning Models\n",
    "def prepare_dl_data(data_path, target_size=(224, 224)):\n",
    "    filenames = [f for f in os.listdir(data_path) if f.endswith('.jpg')]\n",
    "    X, y = [], []\n",
    "    for filename in filenames:\n",
    "        img = Image.open(os.path.join(data_path, filename)).convert('RGB').resize(target_size)\n",
    "        img_array = np.array(img).astype(np.float32) / 255.0\n",
    "        X.append(img_array)\n",
    "        y.append(0 if filename.split('.')[0] == 'cat' else 1)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758bd7f0",
   "metadata": {},
   "source": [
    "This function loads all .jpg images from a folder and preprocesses them for deep learning models such as CNNs. Each image is opened, converted to RGB, resized to 224×224 pixels, and normalized to values between 0 and 1. Unlike the classical ML version, the images are not flattened, rather they are kept as 3D arrays (height × width × channels) so that convolutional layers can learn spatial features. Labels are extracted from the filenames, also assigning 0 for cats and 1 for dogs. The function returns two NumPy arrays: X containing the processed image tensors and y containing the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d1a0c9",
   "metadata": {},
   "source": [
    "## Classical Machine Learning Models\n",
    "\n",
    "To establish a starting point for image classification performance, we first train two classical machine learning models: Support Vector Machines (SVM) and XGBoost. These models serve as baselines before introducing deep learning methods like CNNs. Because classical ML algorithms cannot operate directly on image grids, we use the preprocessed and flattened 64×64 image vectors prepared earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d90a1b9",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c65d1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")  \n",
    "\n",
    "# Calling the preprocessing function\n",
    "from preprocessing import prepare_ml_data\n",
    "\n",
    "# Import necessary libraries for modeling\n",
    "from sklearn.model_selection import train_test_split \n",
    "from xgboost import XGBClassifier \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9222a124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both XGBoost and SVM require 2D input data, so we will flatten the images\n",
    "X, y = prepare_ml_data(\"../data_sample\", target_size=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979dbbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "#save_dir = \"../data/processed\"\n",
    "#os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "#np.save(os.path.join(save_dir, \"X_train.npy\"), X_train)\n",
    "#np.save(os.path.join(save_dir, \"X_test.npy\"), X_test)\n",
    "#np.save(os.path.join(save_dir, \"y_train.npy\"), y_train)\n",
    "#np.save(os.path.join(save_dir, \"y_test.npy\"), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6834cb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions of the datasets\n",
    "print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532e6db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training an XGBoost classifier\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,     # number of boosted trees\n",
    "    max_depth=5,          # tree depth (controls complexity)\n",
    "    learning_rate=0.1,    # boosting shrinkage\n",
    "    subsample=0.8,        # use 80% of samples per tree\n",
    "    colsample_bytree=0.8, # use 80% of features per tree\n",
    "    eval_metric=\"logloss\" # required to suppress warnings for binary classification\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on test set\n",
    "y_pred_xgb = xgb_model.predict(X_test) \n",
    "\n",
    "# Evaluate accuracy\n",
    "xgb_acc = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost Test Accuracy: {xgb_acc:.4f}\")\n",
    "# Test accuracy = 75%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5bc0e3",
   "metadata": {},
   "source": [
    "Since XGBoost doesn't naturally capture spatial patterns (edges, textures, shapes) like CNNs do, we treat it as a baseline model against CNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bce207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train a SVM model\n",
    "\n",
    "svm_model = SVC(kernel=\"linear\") # linear kernel is fast and is commonly used as a baseline model\n",
    "svm_model.fit(X_train, y_train) \n",
    "y_pred_svm = svm_model.predict(X_test) \n",
    "print(\"SVM accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "# Test accuracy = 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4300bf4c",
   "metadata": {},
   "source": [
    "SVM finds the best hyperplane that separates the two classes (cat vs dog). We obtained a test accuracy of 50%, meaning that the model is essentially a coin toss, highlighting the limitations of applying classical machine learning directly to raw image data. Since the images were flattened into long vectors, the spatial relationships between pixels were lost, making it difficult for the SVM to capture meaningful patterns, such as fur texture or shapes. This result motivates the need for models that can exploit the inherent structure of images, such as convolutional neural networks and vision transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fc17b8",
   "metadata": {},
   "source": [
    "# Deep Learning Methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
