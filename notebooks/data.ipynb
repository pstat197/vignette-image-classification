{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c96c063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "import numpy as np\n",
    "from preprocessing import prepare_dl_data\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "\n",
    "data_path = '../data_dl/train'\n",
    "X, y = prepare_dl_data(data_path)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "save_dir = '../data_dl'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "#np.save(f\"{save_dir}/X_train.npy\", X_train)\n",
    "#np.save(f\"{save_dir}/X_test.npy\", X_test)\n",
    "#np.save(f\"{save_dir}/Y_train.npy\", y_train)\n",
    "#np.save(f\"{save_dir}/Y_test.npy\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29e722c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95199963",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rv/cvbrxcnx7nld6j2v05jvc13c0000gn/T/ipykernel_15456/2541430026.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCatDogDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mval_dataset\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mCatDogDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "class CatDogDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X).permute(0, 3, 1, 2).float()\n",
    "        self.y = torch.tensor(y).long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = CatDogDataset(X_train, y_train)\n",
    "val_dataset   = CatDogDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203bff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a48a0ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-1.0.22-py3-none-any.whl.metadata (63 kB)\n",
      "Requirement already satisfied: torch in /Users/alexmorifusa/opt/anaconda3/lib/python3.9/site-packages (from timm) (2.2.2)\n",
      "Requirement already satisfied: torchvision in /Users/alexmorifusa/opt/anaconda3/lib/python3.9/site-packages (from timm) (0.17.2)\n",
      "Requirement already satisfied: pyyaml in /Users/alexmorifusa/opt/anaconda3/lib/python3.9/site-packages (from timm) (6.0)\n",
      "Collecting huggingface_hub (from timm)\n",
      "  Downloading huggingface_hub-1.1.7-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors (from timm)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-macosx_10_12_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: filelock in /Users/alexmorifusa/opt/anaconda3/lib/python3.9/site-packages (from huggingface_hub->timm) (3.6.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub->timm)\n",
      "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface_hub->timm)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-macosx_10_12_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/alexmorifusa/opt/anaconda3/lib/python3.9/site-packages (from huggingface_hub->timm) (0.23.3)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/alexmorifusa/opt/anaconda3/lib/python3.9/site-packages (from huggingface_hub->timm) (21.3)\n",
      "Collecting shellingham (from huggingface_hub->timm)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/alexmorifusa/opt/anaconda3/lib/python3.9/site-packages (from huggingface_hub->timm) (4.64.1)\n",
      "Collecting typer-slim (from huggingface_hub->timm)\n",
      "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/alexmorifusa/opt/anaconda3/lib/python3.9/site-packages (from huggingface_hub->timm) (4.15.0)\n",
      "Requirement already satisfied: certifi in /Users/alexmorifusa/opt/anaconda3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (2025.7.14)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /Users/alexmorifusa/opt/anaconda3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (0.16.3)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in /Users/alexmorifusa/opt/anaconda3/lib/python3.9/site-packages (from rfc3986[idna2008]<2,>=1.3->httpx<1,>=0.23.0->huggingface_hub->timm) (1.5.0)\n",
      "Requirement already satisfied: sniffio in /Users/alexmorifusa/opt/anaconda3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/alexmorifusa/opt/anaconda3/lib/python3.9/site-packages (from httpcore<0.17.0,>=0.15.0->httpx<1,>=0.23.0->huggingface_hub->timm) (0.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /Users/alexmorifusa/opt/anaconda3/lib/python3.9/site-packages (from httpcore<0.17.0,>=0.15.0->httpx<1,>=0.23.0->huggingface_hub->timm) (3.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/alexmorifusa/opt/anaconda3/lib/python3.9/site-packages (from anyio<5.0,>=3.0->httpcore<0.17.0,>=0.15.0->httpx<1,>=0.23.0->huggingface_hub->timm) (3.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/alexmorifusa/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.9->huggingface_hub->timm) (3.0.9)\n",
      "Requirement already satisfied: sympy in /Users/alexmorifusa/opt/anaconda3/lib/python3.9/site-packages (from torch->timm) (1.10.1)\n",
      "Requirement already satisfied: networkx in /Users/alexmorifusa/opt/anaconda3/lib/python3.9/site-packages (from torch->timm) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /Users/alexmorifusa/opt/anaconda3/lib/python3.9/site-packages (from torch->timm) (2.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/alexmorifusa/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch->timm) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/alexmorifusa/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch->timm) (1.2.1)\n",
      "Requirement already satisfied: numpy in /Users/alexmorifusa/opt/anaconda3/lib/python3.9/site-packages (from torchvision->timm) (1.24.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/alexmorifusa/opt/anaconda3/lib/python3.9/site-packages (from torchvision->timm) (9.2.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/alexmorifusa/opt/anaconda3/lib/python3.9/site-packages (from typer-slim->huggingface_hub->timm) (8.0.4)\n",
      "Downloading timm-1.0.22-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-1.1.7-py3-none-any.whl (516 kB)\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-macosx_10_12_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Downloading safetensors-0.7.0-cp38-abi3-macosx_10_12_x86_64.whl (467 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: typer-slim, shellingham, safetensors, hf-xet, fsspec, huggingface_hub, timm\n",
      "\u001b[2K  Attempting uninstall: fsspec\n",
      "\u001b[2K    Found existing installation: fsspec 2022.7.1\n",
      "\u001b[2K    Uninstalling fsspec-2022.7.1:\n",
      "\u001b[2K      Successfully uninstalled fsspec-2022.7.1\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [timm][32m6/7\u001b[0m [timm]ngface_hub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed fsspec-2025.10.0 hf-xet-1.2.0 huggingface_hub-1.1.7 safetensors-0.7.0 shellingham-1.5.4 timm-1.0.22 typer-slim-0.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59c9d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "pretrained_model = timm.create_model(\n",
    "    'vit_base_patch16_224',\n",
    "    pretrained=True,\n",
    "    num_classes=2 \n",
    ")\n",
    "pretrained_model = pretrained_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(pretrained_model.parameters(), lr=1e-4, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aa62f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    pretrained_model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = pretrained_model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_total += y_batch.size(0)\n",
    "        train_correct += predicted.eq(y_batch).sum().item()\n",
    "    \n",
    "    pretrained_model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = pretrained_model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += y_batch.size(0)\n",
    "            val_correct += predicted.eq(y_batch).sum().item()\n",
    "    \n",
    "    train_acc = 100. * train_correct / train_total\n",
    "    val_acc = 100. * val_correct / val_total\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{epochs} - '\n",
    "          f'Train Loss: {train_loss/len(train_loader):.4f}, '\n",
    "          f'Train Acc: {train_acc:.2f}%, '\n",
    "          f'Val Loss: {val_loss/len(val_loader):.4f}, '\n",
    "          f'Val Acc: {val_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290f96a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model.eval()\n",
    "with torch.no_grad():\n",
    "    X_batch, y_batch = next(iter(val_loader))\n",
    "    X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "    outputs = pretrained_model(X_batch)\n",
    "    _, predicted = outputs.max(1)\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    \n",
    "    print(\"\\nSample predictions:\")\n",
    "    for i in range(10):\n",
    "        true_label = 'cat' if y_batch[i] == 0 else 'dog'\n",
    "        pred_label = 'cat' if predicted[i] == 0 else 'dog'\n",
    "        confidence = probs[i][predicted[i]].item() * 100\n",
    "        print(f'True: {true_label}, Pred: {pred_label}, Confidence: {confidence:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
